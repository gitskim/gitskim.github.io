{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d427a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bf1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad36c6",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b47ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "mu_1, sigma_1 = 75, 10\n",
    "exam_1 = np.random.normal(mu_1, sigma_1, N//2)\n",
    "exam_1 = exam_1.astype(int)\n",
    "exam_1 = np.clip(exam_1, 0, 100)\n",
    "mu_2, sigma_2 = 45, 10\n",
    "exam_2 = np.random.normal(mu_2, sigma_2, N//2)\n",
    "exam_2 = exam_2.astype(int)\n",
    "exam_2 = np.clip(exam_2, 0, 100)\n",
    "X = np.concatenate((exam_1, exam_2))\n",
    "Y = np.zeros(N, dtype=np.bool_)\n",
    "Y[:N//2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c0caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(212)\n",
    "_ = ax.hist(exam_1, alpha = 0.5, bins=30)\n",
    "_ = ax2.hist(exam_2, alpha=0.5, bins=30)\n",
    "_ = ax3.hist(exam_1, alpha=0.5, bins=30)\n",
    "_ = ax3.hist(exam_2, alpha = 0.5, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2fdbd",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Let `X[i]` be the final exam score of student `i` and ranges from 0 to 100. Let `Y[i]` be 1 if they got into college and 0 if they didn't. `N` is the total number of students. As a student counselor, you want to know what should be a cutoff for the final exam scores to determine the likelihood of the student getting into college. Calculate the final exam score threshold that yields the highest precision and recall values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa265cd",
   "metadata": {},
   "source": [
    "![Confusion Matrix](https://www.researchgate.net/publication/336402347/figure/fig3/AS:812472659349505@1570719985505/Calculation-of-Precision-Recall-and-Accuracy-in-the-confusion-matrix.ppm \"CM with precision and recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180f4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(ground_truth, model_data):\n",
    "    #print(model_data)\n",
    "    tp = (ground_truth & model_data).sum()\n",
    "    tn = (~ground_truth & ~model_data).sum()\n",
    "    fp = (~ground_truth & model_data).sum()\n",
    "    fn = (ground_truth & ~model_data).sum()\n",
    "    confusion_matrix = np.array([[tp, fp], [fn, tn]])\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a011fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(confusion_matrix):\n",
    "    # tp / (tp + fp)\n",
    "    return confusion_matrix[0][0]/(1e-20 + confusion_matrix[0][0] + confusion_matrix[0][1])\n",
    "\n",
    "def calculate_recall(confusion_matrix):\n",
    "    # tp / (tp + fn)\n",
    "    return confusion_matrix[0][0]/(1e-20 + confusion_matrix[0][0] + confusion_matrix[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1dbdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_f1_score(precision, recall):\n",
    "    # TODO\n",
    "    return 2*(precision * recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c1092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_threshold(X, Y):\n",
    "    nmin = np.min(X)\n",
    "    nmax = np.max(X)\n",
    "    f1_highest = 0\n",
    "    threshold_highest = nmin\n",
    "    for i in range(nmin, nmax + 1): \n",
    "        pred = X > i\n",
    "        cm = create_confusion_matrix(Y, pred)\n",
    "        prec = calculate_precision(cm)\n",
    "        rec = calculate_recall(cm)\n",
    "        f1 = generate_f1_score(prec, rec)\n",
    "        if f1 > f1_highest:\n",
    "            f1_highest = f1\n",
    "            threshold_highest = i\n",
    "            \n",
    "    return f1_highest, threshold_highest\n",
    "\n",
    "calculate_threshold(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a952a",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Assume there is a budget cut in your college counseling department. As a counselor, you can allocate some resources only on those students who are likley to go to college. However, you have to follow no-student-left-behind policy as closely as possible. That is, every student you misclassify as a false-negative, there's a higher penalty. Assuming you get 1 point for true positive and true negative, and -2 points for a false negative and -1 point for false positive, what is the threshold for the final exam score that can predict if a student will go to college or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b758f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gains(ground_truth, model_data):\n",
    "    tp = (ground_truth & model_data).sum()\n",
    "    tn = (~ground_truth & ~model_data).sum()\n",
    "    fp = (~ground_truth & model_data).sum()\n",
    "    fn = (ground_truth & ~model_data).sum()\n",
    "    \n",
    "    return tp + (-1)*fp + (-2)*fn + tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8d0e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_gains(X, Y):\n",
    "    nmin = np.min(X)\n",
    "    nmax = np.max(X)\n",
    "    \n",
    "    gain_highest = 0\n",
    "    threshold = nmin\n",
    "    for i in range(nmin, nmax + 1): \n",
    "        pred = X > i\n",
    "        gain = calculate_gains(Y, pred)\n",
    "        if gain > gain_highest:\n",
    "            gain_highest = gain\n",
    "            threshold = i\n",
    "            \n",
    "    return gain_highest, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc88c39",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "By raising the classification threshold, what happens to precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f660f09",
   "metadata": {},
   "source": [
    "Precision tends to increase, while recall decreases or stays the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336689d3",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "There are two models: one with higher recall and the other with higher precision. Which model is better?\n",
    "None - hard to tell\n",
    "\n",
    "# Problem 5\n",
    "If model A has better precision and better recall than model B, then is model A is a better model?\n",
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8392b",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* https://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-accuracy-precision-recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc982c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
